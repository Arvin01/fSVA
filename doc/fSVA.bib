Automatically generated by Mendeley 1.6
Any changes to this file will be lost if it is regenerated by Mendeley.

@article{Gagnon-Bartsch2011,
abstract = {Microarray expression studies suffer from the problem of batch effects and other unwanted variation. Many methods have been proposed to adjust microarray data to mitigate the problems of unwanted variation. Several of these methods rely on factor analysis to infer the unwanted variation from the data. A central problem with this approach is the difficulty in discerning the unwanted variation from the biological variation that is of interest to the researcher. We present a new method, intended for use in differential expression studies, that attempts to overcome this problem by restricting the factor analysis to negative control genes. Negative control genes are genes known a priori not to be differentially expressed with respect to the biological factor of interest. Variation in the expression levels of these genes can therefore be assumed to be unwanted variation. We name this method “Remove Unwanted Variation, 2-step” (RUV-2). We discuss various techniques for assessing the performance of an adjustment method and compare the performance of RUV-2 with that of other commonly used adjustment methods such as Combat and Surrogate Variable Analysis (SVA). We present several example studies, each concerning genes differentially expressed with respect to gender in the brain and find that RUV-2 performs as well or better than other methods. Finally, we discuss the possibility of adapting RUV-2 for use in studies not concerned with differential expression and conclude that there may be promise but substantial challenges remain.},
author = {Gagnon-Bartsch, Johann A and Speed, Terence P},
doi = {10.1093/biostatistics/kxr034},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Gagnon-Bartsch, Speed - 2012 - Using control genes to correct for unwanted variation in microarray data.pdf:pdf},
issn = {1465-4644},
journal = {Biostatistics},
keywords = {batch effect,control gene,differential expression,factor analysis,sva,unwanted variation},
month = nov,
number = {3},
pages = {539----552},
title = {{Using control genes to correct for unwanted variation in microarray data}},
url = {http://dx.doi.org/10.1093/biostatistics/kxr034},
volume = {13},
year = {2012}
}
@article{Walker2008,
abstract = {Non-biological experimental error routinely occurs in microarray data collected in different batches. It is often impossible to compare groups of samples from independent experiments because batch effects confound true gene expression differences. Existing methods can correct for batch effects only when samples from all biological groups are represented in every batch.},
author = {Walker, Wynn L and Liao, Isaac H and Gilbert, Donald L and Wong, Brenda and Pollard, Katherine S and McCulloch, Charles E and Lit, Lisa and Sharp, Frank R},
doi = {10.1186/1471-2164-9-494},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Walker et al. - 2008 - Empirical Bayes accomodation of batch-effects in microarray data using identical replicate reference samples application to RNA expression profiling of blood from Duchenne muscular dystrophy p.pdf:pdf},
issn = {1471-2164},
journal = {BMC genomics},
keywords = {Bayes Theorem,Duchenne,Duchenne: genetics,Gene Expression Profiling,Gene Expression Profiling: methods,Humans,Muscular Dystrophy,Oligonucleotide Array Sequence Analysis,Oligonucleotide Array Sequence Analysis: methods,RNA,RNA: blood,RNA: metabolism,Reference Standards},
month = jan,
pages = {494},
pmid = {18937867},
title = {{Empirical Bayes accomodation of batch-effects in microarray data using identical replicate reference samples: application to RNA expression profiling of blood from Duchenne muscular dystrophy patients.}},
url = {http://dx.doi.org/10.1186/1471-2164-9-494},
volume = {9},
year = {2008}
}
@article{Leek2007,
abstract = {It has unambiguously been shown that genetic, environmental, demographic, and technical factors may have substantial effects on gene expression levels. In addition to the measured variable(s) of interest, there will tend to be sources of signal due to factors that are unknown, unmeasured, or too complicated to capture through simple models. We show that failing to incorporate these sources of heterogeneity into an analysis can have widespread and detrimental effects on the study. Not only can this reduce power or induce unwanted dependence across genes, but it can also introduce sources of spurious signal to many genes. This phenomenon is true even for well-designed, randomized studies. We introduce "surrogate variable analysis" (SVA) to overcome the problems caused by heterogeneity in expression studies. SVA can be applied in conjunction with standard analysis techniques to accurately capture the relationship between expression and any modeled variables of interest. We apply SVA to disease class, time course, and genetics of gene expression studies. We show that SVA increases the biological accuracy and reproducibility of analyses in genome-wide expression studies.},
annote = {                                                                        SVA Paper                                                                  },
author = {Leek, Jeffrey T and Storey, John D},
doi = {10.1371/journal.pgen.0030161},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Leek, Storey - 2007 - Capturing heterogeneity in gene expression studies by surrogate variable analysis.pdf:pdf},
issn = {1553-7404},
journal = {PLoS Genetics},
keywords = {Algorithms,BRCA1,BRCA2,Breast Neoplasms,Breast Neoplasms: genetics,Computer Simulation,Data Interpretation,Epigenesis,Female,Fungal,Gene Expression,Genes,Genetic,Genetic Heterogeneity,Genetic Linkage,Genome,Heritable,Human,Humans,Kidney,Kidney: metabolism,Linear Models,Mutation,Oligonucleotide Array Sequence Analysis,Quantitative Trait,Reproducibility of Results,Saccharomyces cerevisiae,Saccharomyces cerevisiae: genetics,Saccharomyces cerevisiae: metabolism,Statistical,Time Factors},
month = sep,
number = {9},
pages = {1724--35},
pmid = {17907809},
title = {{Capturing heterogeneity in gene expression studies by surrogate variable analysis.}},
url = {http://dx.doi.org/10.1371/journal.pgen.0030161},
volume = {3},
year = {2007}
}
@article{Efron2004b,
abstract = {Current scientific techniques in genomics and image processing routinely produce hypothesis testing problems with hundreds or thousands of cases to consider simultaneously. This poses new difficulties for the statistician, but also opens new opportunities. In particular, it allows empirical estimation of an appropriate null hypothesis. The empirical null may be considerably more dispersed than the usual theoretical null distribution that would be used for any one case considered separately. An empirical Bayes analysis plan for this situation is developed, using a local version of the false discovery rate to examine the inference issues. Two genomics problems are used as examples to show the importance of correctly choosing the null hypothesis.},
author = {Efron, Bradley},
doi = {10.1198/016214504000000089},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Efron - 2004 - Large-Scale Simultaneous Hypothesis Testing(2).pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {empirical bayes,empirical null hypothesis,local false discovery rate,microarray analysis,unobserved covariates},
month = mar,
number = {465},
pages = {96--104},
title = {{Large-Scale Simultaneous Hypothesis Testing}},
url = {http://dx.doi.org/10.1198/016214504000000089},
volume = {99},
year = {2004}
}
@article{Friguet2009,
abstract = {The impact of dependence between individual test statistics is currently among the most discussed topics in the multiple testing of high-dimensional data literature, especially since Benjamini and Hochberg (1995) introduced the false discovery rate (FDR). Many papers have first focused on the impact of dependence on the control of the FDR. Some more recent works have investigated approaches that account for common information shared by all the variables to stabilize the distribution of the error rates. Similarly, we propose to model this sharing of information by a factor analysis structure for the conditional variance of the test statistics. It is shown that the variance of the number of false discoveries increases along with the fraction of common variance. Test statistics for general linear contrasts are deduced, taking advantage of the common factor structure to reduce the variance of the error rates. A conditional FDR estimate is proposed and the overall performance of multiple testing procedure is shown to be markedly improved, regarding the nondiscovery rate, with respect to classical procedures. The present methodology is also assessed by comparison with leading multiple testing methods.},
author = {Friguet, Chlo\'{e} and Kloareg, Maela and Causeur, David},
doi = {10.1198/jasa.2009.tm08332},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Friguet, Kloareg, Causeur - 2009 - A Factor Model Approach to Multiple Testing Under Dependence.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {factor analysis,false discovery rate,multiple-hypothesis testing,nondiscovery rate},
month = dec,
number = {488},
pages = {1406--1415},
title = {{A Factor Model Approach to Multiple Testing Under Dependence}},
url = {http://dx.doi.org/10.1198/jasa.2009.tm08332},
volume = {104},
year = {2009}
}
@article{Spielman2007,
abstract = {Variation in DNA sequence contributes to individual differences in quantitative traits, but in humans the specific sequence variants are known for very few traits. We characterized variation in gene expression in cells from individuals belonging to three major population groups. This quantitative phenotype differs significantly between European-derived and Asian-derived populations for 1,097 of 4,197 genes tested. For the phenotypes with the strongest evidence of cis determinants, most of the variation is due to allele frequency differences at cis-linked regulators. The results show that specific genetic variation among populations contributes appreciably to differences in gene expression phenotypes. Populations differ in prevalence of many complex genetic diseases, such as diabetes and cardiovascular disease. As some of these are probably influenced by the level of gene expression, our results suggest that allele frequency differences at regulatory polymorphisms also account for some population differences in prevalence of complex diseases.},
author = {Spielman, Richard S and Bastone, Laurel a and Burdick, Joshua T and Morley, Michael and Ewens, Warren J and Cheung, Vivian G},
doi = {10.1038/ng1955},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Spielman et al. - 2007 - Common genetic variants account for differences in gene expression among ethnic groups.pdf:pdf},
issn = {1061-4036},
journal = {Nature genetics},
keywords = {Ethnic Groups,Ethnic Groups: genetics,European Continental Ancestry Group,Gene Expression,Gene Expression Profiling,Gene Frequency,Genetic Variation,Genetics,Humans,Japan,Phenotype,Polymorphism,Population,Single Nucleotide},
month = feb,
number = {2},
pages = {226--31},
pmid = {17206142},
title = {{Common genetic variants account for differences in gene expression among ethnic groups.}},
url = {http://dx.doi.org/10.1038/ng1955},
volume = {39},
year = {2007}
}
@article{Akey2007,
author = {Akey, Joshua M and Biswas, Shameek and Leek, Jeffrey T and Storey, John D},
doi = {10.1038/ng0707-807},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Akey et al. - 2007 - On the design and analysis of gene expression studies in human populations.pdf:pdf},
issn = {1061-4036},
journal = {Nature Genetics},
keywords = {Asian Continental Ancestry Group,European Continental Ancestry Group,Gene Expression Profiling,Genetic Variation,Genetics,Humans,Oligonucleotide Array Sequence Analysis,Population},
month = jul,
number = {7},
pages = {807--8; author reply 808--9},
pmid = {17597765},
title = {{On the design and analysis of gene expression studies in human populations.}},
url = {http://dx.doi.org/10.1038/ng0707-807},
volume = {39},
year = {2007}
}
@article{Scharpf2011,
abstract = {Submicroscopic changes in chromosomal DNA copy number dosage are common and have been implicated in many heritable diseases and cancers. Recent high-throughput technologies have a resolution that permits the detection of segmental changes in DNA copy number that span thousands of base pairs in the genome. Genomewide association studies (GWAS) may simultaneously screen for copy number phenotype and single nucleotide polymorphism (SNP) phenotype associations as part of the analytic strategy. However, genomewide array analyses are particularly susceptible to batch effects as the logistics of preparing DNA and processing thousands of arrays often involves multiple laboratories and technicians, or changes over calendar time to the reagents and laboratory equipment. Failure to adjust for batch effects can lead to incorrect inference and requires inefficient post hoc quality control procedures to exclude regions that are associated with batch. Our work extends previous model-based approaches for copy number estimation by explicitly modeling batch and using shrinkage to improve locus-specific estimates of copy number uncertainty. Key features of this approach include the use of biallelic genotype calls from experimental data to estimate batch-specific and locus-specific parameters of background and signal without the requirement of training data. We illustrate these ideas using a study of bipolar disease and a study of chromosome 21 trisomy. The former has batch effects that dominate much of the observed variation in the quantile-normalized intensities, while the latter illustrates the robustness of our approach to a data set in which approximately 27\% of the samples have altered copy number. Locus-specific estimates of copy number can be plotted on the copy number scale to investigate mosaicism and guide the choice of appropriate downstream approaches for smoothing the copy number as a function of physical position. The software is open source and implemented in the R package crlmm at Bioconductor (http:www.bioconductor.org).},
annote = {Copy number batch},
author = {Scharpf, Robert B and Ruczinski, Ingo and Carvalho, Benilton and Doan, Betty and Chakravarti, Aravinda and Irizarry, Rafael a},
doi = {10.1093/biostatistics/kxq043},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Scharpf et al. - 2011 - A multilevel model to address batch effects in copy number estimation using SNP arrays.pdf:pdf},
issn = {1468-4357},
journal = {Biostatistics (Oxford, England)},
keywords = {Algorithms,Bipolar Disorder,Bipolar Disorder: genetics,Down Syndrome,Down Syndrome: genetics,Gene Dosage,Gene Dosage: genetics,Genetic,Genetic Variation,Genetic Variation: genetics,Genome-Wide Association Study,Genome-Wide Association Study: methods,Genotype,Humans,Models,Polymorphism,Single Nucleotide,Single Nucleotide: genetics,Statistical},
month = jan,
number = {1},
pages = {33--50},
pmid = {20625178},
title = {{A multilevel model to address batch effects in copy number estimation using SNP arrays.}},
url = {http://dx.doi.org/10.1093/biostatistics/kxq043},
volume = {12},
year = {2011}
}
@article{Buja1992,
abstract = {We investigate parallel analysis (PA), a selection rule for the number-of-factors problem, from the point of view of permutation assessment. The idea of applying permutation test ideas to PA leads to a quasi-inferential, non-parametric version of PA which accounts not only for finite-sample bias but sampling variability as well. We give evidence, however, that quasi-inferential PA based on normal random variates (as opposed to data permutations) is surprisingly independent of distributional assumptions, and enjoys therefore certain non- parametric properties as well. This is a justification for providing tables for quasi-inferential PA. Based on permutation theory, we compare PA of principal components with PA of principal factor analysis and show that PA of principal factors may tend to select too many factors. We also apply parallel analysis to so-called resistant correlations and give evidence that this yields a slightly more conservative factor selection method. Finally, we apply PA to loadings and show how this provides benchmark values for loadings which are sensitive to the number of variables, number of subjects, and order of factors. These values therefore improve on conventional fixed thresholds such as 0.5 or 0.8 which are used irrespective of the size of the data},
author = {Buja, Andreas and Eyuboglu, Nermin},
doi = {10.1207/s15327906mbr2704\_2},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Buja, Eyuboglu - 1992 - Remarks on Parallel Analysis.pdf:pdf},
journal = {Multivariate Behavioral Research},
number = {4},
pages = {509--540},
title = {{Remarks on Parallel Analysis}},
url = {http://dx.doi.org/10.1207/s15327906mbr2704\_2},
volume = {27},
year = {1992}
}
@article{Leek2008,
abstract = {We develop a general framework for performing large-scale significance testing in the presence of arbitrarily strong dependence. We derive a low-dimensional set of random vectors, called a dependence kernel, that fully captures the dependence structure in an observed high-dimensional dataset. This result shows a surprising reversal of the "curse of dimensionality" in the high-dimensional hypothesis testing setting. We show theoretically that conditioning on a dependence kernel is sufficient to render statistical tests independent regardless of the level of dependence in the observed data. This framework for multiple testing dependence has implications in a variety of common multiple testing problems, such as in gene expression studies, brain imaging, and spatial epidemiology.},
annote = {Proving stuff about dependence for the model 
        
X = BS + $\backslash$Gamma G + U},
author = {Leek, Jeffrey T and Storey, John D},
doi = {10.1073/pnas.0808709105},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Leek, Storey - 2008 - A general framework for multiple testing dependence.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Algorithms,Computer Simulation,Models,Software,Statistical,Statistics as Topic},
month = dec,
number = {48},
pages = {18718--23},
pmid = {19033188},
title = {{A general framework for multiple testing dependence}},
url = {http://dx.doi.org/10.1073/pnas.0808709105},
volume = {105},
year = {2008}
}
@article{Sebastiani2010,
abstract = {Healthy aging is thought to reflect the combined influence of environmental factors (lifestyle choices) and genetic factors. To explore the genetic contribution, we undertook a genome-wide association study of exceptional longevity (EL) in 1055 centenarians and 1267 controls. Using these data, we built a genetic model that includes 150 single-nucleotide polymorphisms (SNPs) and found that it could predict EL with 77\% accuracy in an independent set of centenarians and controls. Further in silico analysis revealed that 90\% of centenarians can be grouped into 19 clusters characterized by different combinations of SNP genotypes—or genetic signatures—of varying predictive value. The different signatures, which attest to the genetic complexity of EL, correlated with differences in the prevalence and age of onset of age-associated diseases (e.g., dementia, hypertension, and cardiovascular disease) and may help dissect this complex phenotype into subphenotypes of healthy aging.},
annote = {retracted longevity GWAS study},
author = {Sebastiani, Paola and Solovieff, Nadia and Puca, Annibale and Hartley, Stephen W and Melista, Efthymia and Dworkis, Daniel A and Wilk, Jemma B and Myers, Richard H and Steinberg, Martin H and Baldwin, Clinton T and Perls, Thomas T},
doi = {10.1126/science.1190532},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Sebastiani et al. - 2010 - Genetic Signatures of Exceptional Longevity in Humans.pdf:pdf},
journal = {Science},
pages = {1126},
title = {{Genetic Signatures of Exceptional Longevity in Humans}},
url = {http://dx.doi.org/10.1126/science.1190532},
volume = {10},
year = {2010}
}
@article{Edgar2002,
abstract = {The Gene Expression Omnibus (GEO) project was initiated in response to the growing demand for a public repository for high-throughput gene expression data. GEO provides a flexible and open design that facilitates submission, storage and retrieval of heterogeneous data sets from high-throughput gene expression and genomic hybridization experiments. GEO is not intended to replace in house gene expression databases that benefit from coherent data sets, and which are constructed to facilitate a particular analytic method, but rather complement these by acting as a tertiary, central data distribution hub. The three central data entities of GEO are platforms, samples and series, and were designed with gene expression and genomic hybridization experiments in mind. A platform is, essentially, a list of probes that define what set of molecules may be detected. A sample describes the set of molecules that are being probed and references a single platform used to generate its molecular abundance data. A series organizes samples into the meaningful data sets which make up an experiment. The GEO repository is publicly accessible through the World Wide Web at http://www.ncbi.nlm.nih.gov/geo.},
author = {Edgar, Ron and Domrachev, Michael and Lash, Alex E},
doi = {10.1093/nar/30.1.207},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Edgar, Domrachev, Lash - 2002 - Gene Expression Omnibus NCBI gene expression and hybridization array data repository.pdf:pdf},
issn = {1362-4962},
journal = {Nucleic Acids Research},
keywords = {Animals,Communication,Database Management Systems,Databases,Forecasting,Gene Expression Profiling,Genetic,Genome,Humans,Information Storage and Retrieval,Internet,National Library of Medicine (U.S.),Oligonucleotide Array Sequence Analysis,United States},
month = jan,
number = {1},
pages = {207--10},
pmid = {11752295},
title = {{Gene Expression Omnibus: NCBI gene expression and hybridization array data repository}},
url = {http://dx.doi.org/10.1093/nar/30.1.207},
volume = {30},
year = {2002}
}
@article{Luo2010,
abstract = {Batch effects are the systematic non-biological differences between batches (groups) of samples in microarray experiments due to various causes such as differences in sample preparation and hybridization protocols. Previous work focused mainly on the development of methods for effective batch effects removal. However, their impact on cross-batch prediction performance, which is one of the most important goals in microarray-based applications, has not been addressed. This paper uses a broad selection of data sets from the Microarray Quality Control Phase II (MAQC-II) effort, generated on three microarray platforms with different causes of batch effects to assess the efficacy of their removal. Two data sets from cross-tissue and cross-platform experiments are also included. Of the 120 cases studied using Support vector machines (SVM) and K nearest neighbors (KNN) as classifiers and Matthews correlation coefficient (MCC) as performance metric, we find that Ratio-G, Ratio-A, EJLR, mean-centering and standardization methods perform better or equivalent to no batch effect removal in 89, 85, 83, 79 and 75\% of the cases, respectively, suggesting that the application of these methods is generally advisable and ratio-based methods are preferred.},
author = {Luo, J and Schumacher, M and Scherer, A and Sanoudou, D and Megherbi, D and Davison, T and Shi, T and Tong, W and Shi, L and Hong, H and Zhao, C and Elloumi, F and Shi, W and Thomas, R and Lin, S and Tillinghast, G and Liu, G and Zhou, Y and Herman, D and Li, Y and Deng, Y and Fang, H and Bushel, P and Woods, M and Zhang, J},
doi = {10.1038/tpj.2010.57},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Luo et al. - 2010 - A comparison of batch effect removal methods for enhancement of prediction performance using MAQC-II microarray gene expression data.pdf:pdf},
issn = {1473-1150},
journal = {The Pharmacogenomics Journal},
keywords = {Algorithms,Breast Neoplasms,Breast Neoplasms: drug therapy,Breast Neoplasms: genetics,Databases,Female,Gene Expression Profiling,Gene Expression Profiling: methods,Gene Expression Profiling: standards,Genetic,Humans,Liver Neoplasms,Liver Neoplasms: drug therapy,Liver Neoplasms: genetics,Oligonucleotide Array Sequence Analysis,Oligonucleotide Array Sequence Analysis: methods,Oligonucleotides,Oligonucleotides: diagnostic use,Predictive Value of Tests,Quality Control,Reference Standards,Reproducibility of Results,Toxicogenetics,Toxicogenetics: statistics \& numerical data},
month = aug,
number = {4},
pages = {278--91},
pmid = {20676067},
title = {{A comparison of batch effect removal methods for enhancement of prediction performance using MAQC-II microarray gene expression data}},
url = {http://dx.doi.org/10.1038/tpj.2010.57},
volume = {10},
year = {2010}
}
@book{Micheel2012,
abstract = {Technologies collectively called omics enable simultaneous measurement of an enormous number of biomolecules; for example, genomics investigates thousands of DNA sequences, and proteomics examines large numbers of proteins. Scientists are using these technologies to develop innovative tests to detect disease and to predict a patient's likelihood of responding to specific drugs. Following a recent case involving premature use of omics-based tests in cancer clinical trials at Duke University, the NCI requested that the IOM establish a committee to recommend ways to strengthen omics-based test development and evaluation. This report identifies best practices to enhance development, evaluation, and translation of omics-based tests while simultaneously reinforcing steps to ensure that these tests are appropriately assessed for scientific validity before they are used to guide patient treatment in clinical trials.},
author = {Micheel, Christine M and Nass, Sharyl J and Omenn, Gilbert S},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Micheel, Nass, Omenn - 2012 - Evolution of Translational Omics Lessons Learned and the Path Forward.pdf:pdf},
isbn = {9780309224185},
publisher = {The National Academies Press},
title = {{Evolution of Translational Omics: Lessons Learned and the Path Forward}},
url = {http://www.nap.edu/openbook.php?record\_id=13297},
year = {2012}
}
@article{Parker2012,
abstract = {Measurements from microarrays and other high-throughput technologies are susceptible to non-biological artifacts like batch effects. It is known that batch effects can alter or obscure the set of significant results and biological conclusions in high-throughput studies. Here we examine the impact of batch effects on predictors built from genomic technologies. To investigate batch effects, we collected publicly available gene expression measurements with known outcomes, and estimated batches using date. Using these data we show (1) the impact of batch effects on prediction depends on the correlation between outcome and batch in the training data, and (2) removing expression measurements most affected by batch before building predictors may improve the accuracy of those predictors. These results suggest that (1) training sets should be designed to minimize correlation between batches and outcome, and (2) methods for identifying batch-affected probes should be developed to improve prediction results for studies with high correlation between batches and outcome.},
author = {Parker, Hilary S. and Leek, Jeffrey T.},
doi = {10.1515/1544-6115.1766},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Parker, Leek - 2012 - The practical effect of batch on genomic prediction.pdf:pdf},
issn = {1544-6115},
journal = {Statistical Applications in Genetics and Molecular Biology},
keywords = {batch effects,microarrays,prediction,reproducibility,research design},
month = jan,
number = {3},
title = {{The practical effect of batch on genomic prediction}},
url = {http://dx.doi.org/10.1515/1544-6115.1766},
volume = {11},
year = {2012}
}
@article{Johnson2007b,
abstract = {Non-biological experimental variation or "batch effects" are commonly observed across multiple batches of microarray experiments, often rendering the task of combining data from these batches difficult. The ability to combine microarray data sets is advantageous to researchers to increase statistical power to detect biological phenomena from studies where logistical considerations restrict sample size or in studies that require the sequential hybridization of arrays. In general, it is inappropriate to combine data sets without adjusting for batch effects. Methods have been proposed to filter batch effects from data, but these are often complicated and require large batch sizes ( > 25) to implement. Because the majority of microarray studies are conducted using much smaller sample sizes, existing methods are not sufficient. We propose parametric and non-parametric empirical Bayes frameworks for adjusting data for batch effects that is robust to outliers in small sample sizes and performs comparable to existing methods for large samples. We illustrate our methods using two example data sets and show that our methods are justifiable, easy to apply, and useful in practice. Software for our method is freely available at: http://biosun1.harvard.edu/complab/batch/.},
annote = {                                                                        Combat Paper
                                                                                
Overall idea:"We propose parametric and non-parametric empirical Bayes frameworks for adjusting data for batch effects that is robust to outliers in small sample sizes and performs comparable to existing methods for large samples."
"EB methods are primarily designed to "borrow information" across genes and experimental conditions in hope that the borrowed information will lead to better estimates or more stable inferences.Other Methods:Normalization - does not adjust for batch effects, so not sufficient
SVD (singular value decomposition) - "adjusting 'the data by filtering out those eigengenes (and eigenarrays) that are inferred to represent noise or experimental artifacts.'"Vectors must be orthogonal, might not be due to batch.DWD (distance weighted discrimination) - finds separate hyper-plane between two batchesCan only use two batchesLocation and scale arguments - Need to have big samples sizes (true for SVD, DWD as well).Standardize by subtracting out mean, standardize variancesBasic location and scale equation: Yijg=$\alpha$g+X$\beta$G+$\gamma$ig+$\delta$ig$\epsilon$ijg 
for gene g for sample j from batch i, where Y is the expression value, $\alpha$ is the overall gene expression, X is the design matrix for sample conditions, $\gamma$ and $\delta$ are the additive and multiplicative batch effects, and the error $\epsilon$ can be assumed to be normal with mean 0 and variance $\sigma$G2.
        
So to correct for the batch effects (taking into account multiplicative errors, which makes it tricky), you would solve for:
Yijg*=Yijg-$\alpha$\^{}g-X$\beta$g\^{}-$\gamma$\^{}ig$\delta$\^{}ig+$\alpha$\^{}g+X$\beta$\^{}gEB methodVariation/expanion on L/S arguments - borrows information across genes so that smaller samples can be used and they won't be influenced by outliers.
Important assumption! - Assumes the phenomena resulting in batch effects often affect many genes in similar ways.
Steps:Step 1: Standardize data by subtracting out gene expression and treatment effect, and adjust for SE.
Step 2: Estimate BE parameters using parametric empirical bayes.Assume standardized data follows normal, then the hyperparameters are: mean \~{} normal, variance \~{} inverse gamma (conjugate priors)
Hyperparameters estimated using method of moments.
In one case, the data did not fit, so they used a non-parametric prior instead.Steps (with equations):
Step 1: Use L/S equation from above, estimate parameters using OLS (constraining ∑ini$\gamma$\^{}ig=0). Then estimate $\sigma$\^{}g2=1N∑ij(Yijg-$\alpha$\^{}g-X$\beta$\^{}g-$\gamma$\^{}ig)2. So the standardized data then is:
Zijg=Yijg-$\alpha$\^{}g-X$\beta$\^{}g$\sigma$\^{}g
        
Step 2: Empirical Bayes: Hyperparameters estimated for standardized data - conjugate priors! Estimated using method of moments.
Zijg∼N($\gamma$ig,$\delta$ig2)
$\gamma$ig∼N($\gamma$i,$\tau$i2)
$\delta$ig2∼InverseGamma($\lambda$i,$\theta$i)
        
Step 3: Adjusting Data for Batch Effects:
Yijg*=$\sigma$\^{}g$\delta$\^{}ig*(Zijg-$\gamma$\^{}ig*)+$\alpha$\^{}g+X$\beta$\^{}g.
Can use these to find the conditional posterior means (equations in paper but I haven't written them out). 
        
Of note! Jeff mentioned in weekly meeting that these were normalized using dChip normalization - when you use RMA, the batch effects are not as pronounced. Try to think of reasons why this might be the case.},
author = {Johnson, W Evan and Li, Cheng and Rabinovic, Ariel},
doi = {10.1093/biostatistics/kxj037},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Johnson, Li, Rabinovic - 2007 - Adjusting batch effects in microarray expression data using empirical Bayes methods.pdf:pdf},
issn = {1465-4644},
journal = {Biostatistics},
keywords = {Bayes Theorem,Data Interpretation,Gene Expression Profiling,Gene Expression Profiling: methods,Humans,Oligonucleotide Array Sequence Analysis,Oligonucleotide Array Sequence Analysis: methods,Statistical},
month = jan,
number = {1},
pages = {118--27},
pmid = {16632515},
title = {{Adjusting batch effects in microarray expression data using empirical Bayes methods.}},
url = {http://dx.doi.org/10.1093/biostatistics/kxj037},
volume = {8},
year = {2007}
}
@article{Lambert2012,
abstract = {Many public and private genome-wide association studies that we have analyzed include flaws in design, with avoidable confounding appearing as a norm rather than the exception. Rather than recognizing flawed research design and addressing that, a category of quality-control statistical methods has arisen to treat only the symptoms. Reflecting more deeply, we examine elements of current genomic research in light of the traditional scientific method and find that hypotheses are often detached from data collection, experimental design, and causal theories. Association studies independent of causal theories, along with multiple testing errors, too often drive health care and public policy decisions. In an era of large-scale biological research, we ask questions about the role of statistical analyses in advancing coherent theories of diseases and their mechanisms. We advocate for reinterpretation of the scientific method in the context of large-scale data analysis opportunities and for renewed appreciation of falsifiable hypotheses, so that we can learn more from our best mistakes.},
author = {Lambert, Christophe G and Black, Laura J},
doi = {10.1093/biostatistics/kxr055},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Lambert, Black - 2012 - Learning from our GWAS mistakes from experimental design to scientific method.pdf:pdf},
issn = {1468-4357},
journal = {Biostatistics (Oxford, England)},
keywords = {Biostatistics,Data Collection,Data Interpretation,Genetic,Genome-Wide Association Study,Genome-Wide Association Study: methods,Genome-Wide Association Study: statistics \& numeri,Humans,Models,Statistical},
month = apr,
number = {2},
pages = {195--203},
pmid = {22285994},
title = {{Learning from our GWAS mistakes: from experimental design to scientific method.}},
url = {http://dx.doi.org/10.1093/biostatistics/kxr055},
volume = {13},
year = {2012}
}
@article{Warmuth2007,
abstract = {We design an on-line algorithm for Principal Component Analysis. In each trial the current instance is projected onto a probabilistically chosen low dimen- sional subspace. The total expected quadratic approximation error equals the total quadratic approximation error of the best subspace chosen in hindsight plus some additional term that grows linearly in dimension of the subspace but logarithmically in the dimension of the instances.},
author = {Warmuth, Manfred K and Kuzmin, Dima},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Warmuth, Kuzmin - 2007 - Randomized PCA Algorithms with Regret Bounds that are Logarithmic in the Dimension.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
pages = {1481},
title = {{Randomized PCA Algorithms with Regret Bounds that are Logarithmic in the Dimension}},
url = {http://books.nips.cc/papers/files/nips19/NIPS2006\_0521.pdf},
volume = {19},
year = {2007}
}
@article{Fare2003,
abstract = {A data anomaly was observed that affected the uniformity and reproducibility of fluorescent signal across DNA microarrays. Results from experimental sets designed to identify potential causes (from microarray production to array scanning) indicated that the anomaly was linked to a batch process; further work allowed us to localize the effect to the posthybridization array stringency washes. Ozone levels were monitored and highly correlated with the batch effect. Controlled exposures of microarrays to ozone confirmed this factor as the root cause, and we present data that show susceptibility of a class of cyanine dyes (e.g., Cy5, Alexa 647) to ozone levels as low as 5-10 ppb for periods as short as 10-30 s. Other cyanine dyes (e.g., Cy3, Alexa 555) were not significantly affected until higher ozone levels (> 100 ppb). To address this environmental effect, laboratory ozone levels should be kept below 2 ppb (e.g., with filters in HVAC) to achieve high quality microarray data.},
author = {Fare, Thomas L and Coffey, Ernest M and Dai, Hongyue and He, Yudong D and Kessler, Deborah a and Kilian, Kristopher a and Koch, John E and LeProust, Eric and Marton, Matthew J and Meyer, Michael R and Stoughton, Roland B and Tokiwa, George Y and Wang, Yanqun},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Fare et al. - 2003 - Effects of atmospheric ozone on microarray data quality.pdf:pdf},
issn = {0003-2700},
journal = {Analytical chemistry},
keywords = {Artifacts,Atmosphere,Atmosphere: chemistry,Carbocyanines,Carbocyanines: chemistry,Desiccation,Fluorescence,Oligonucleotide Array Sequence Analysis,Oligonucleotide Array Sequence Analysis: instrumen,Oligonucleotide Array Sequence Analysis: standards,Ozone,Ozone: analysis,Ozone: chemistry,Quality Control,Reproducibility of Results},
month = sep,
number = {17},
pages = {4672--5},
pmid = {14632079},
title = {{Effects of atmospheric ozone on microarray data quality.}},
url = {http://dx.doi.org/10.1021/ac034241b},
volume = {75},
year = {2003}
}
@article{McCall2011,
abstract = {Microarray technology has become a widely used tool in the biological sciences. Over the past decade, the number of users has grown exponentially, and with the number of applications and secondary data analyses rapidly increasing, we expect this rate to continue. Various initiatives such as the External RNA Control Consortium (ERCC) and the MicroArray Quality Control (MAQC) project have explored ways to provide standards for the technology. For microarrays to become generally accepted as a reliable technology, statistical methods for assessing quality will be an indispensable component; however, there remains a lack of consensus in both defining and measuring microarray quality.},
author = {McCall, Matthew N and Murakami, Peter N and Lukk, Margus and Huber, Wolfgang and Irizarry, Rafael a},
doi = {10.1186/1471-2105-12-137},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/McCall et al. - 2011 - Assessing affymetrix GeneChip microarray quality.pdf:pdf},
issn = {1471-2105},
journal = {BMC bioinformatics},
month = jan,
number = {1},
pages = {137},
pmid = {21548974},
publisher = {BioMed Central Ltd},
title = {{Assessing affymetrix GeneChip microarray quality.}},
url = {http://dx.doi.org/10.1186/1471-2105-12-137},
volume = {12},
year = {2011}
}
@article{Leek2011,
abstract = {High-dimensional data, such as those obtained from a gene expression microarray or second generation sequencing experiment, consist of a large number of dependent features measured on a small number of samples. One of the key problems in genomics is the identification and estimation of factors that associate with many features simultaneously. Identifying the number of factors is also important for unsupervised statistical analyses such as hierarchical clustering. A conditional factor model is the most common model for many types of genomic data, ranging from gene expression, to single nucleotide polymorphisms, to methylation. Here we show that under a conditional factor model for genomic data with a fixed sample size, the right singular vectors are asymptotically consistent for the unobserved latent factors as the number of features diverges. We also propose a consistent estimator of the dimension of the underlying conditional factor model for a finite fixed sample size and an infinite number of features based on a scaled eigen-decomposition. We propose a practical approach for selection of the number of factors in real data sets, and we illustrate the utility of these results for capturing batch and other unmodeled effects in a microarray experiment using the dependence kernel approach of Leek and Storey (2008, Proceedings of the National Academy of Sciences of the United States of America 105, 18718-18723).},
author = {Leek, Jeffrey T},
doi = {10.1111/j.1541-0420.2010.01455.x},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Leek - 2011 - Asymptotic conditional singular value decomposition for high-dimensional genomic data.pdf:pdf},
issn = {1541-0420},
journal = {Biometrics},
keywords = {Genomics,Genomics: methods,Genomics: statistics \& numerical data,Models,Oligonucleotide Array Sequence Analysis,Sample Size,Statistical},
month = jun,
number = {2},
pages = {344--52},
pmid = {20560929},
title = {{Asymptotic conditional singular value decomposition for high-dimensional genomic data.}},
url = {http://dx.doi.org/10.1111/j.1541-0420.2010.01455.x},
volume = {67},
year = {2011}
}
@article{Storey2005,
abstract = {With the ability to measure thousands of related phenotypes from a single biological sample, it is now feasible to genetically dissect systems-level biological phenomena. The genetics of transcriptional regulation and protein abundance are likely to be complex, meaning that genetic variation at multiple loci will influence these phenotypes. Several recent studies have investigated the role of genetic variation in transcription by applying traditional linkage analysis methods to genomewide expression data, where each gene expression level was treated as a quantitative trait and analyzed separately from one another. Here, we develop a new, computationally efficient method for simultaneously mapping multiple gene expression quantitative trait loci that directly uses all of the available data. Information shared across gene expression traits is captured in a way that makes minimal assumptions about the statistical properties of the data. The method produces easy-to-interpret measures of statistical significance for both individual loci and the overall joint significance of multiple loci selected for a given expression trait. We apply the new method to a cross between two strains of the budding yeast Saccharomyces cerevisiae, and estimate that at least 37\% of all gene expression traits show two simultaneous linkages, where we have allowed for epistatic interactions. Pairs of jointly linking quantitative trait loci are identified with high confidence for 170 gene expression traits, where it is expected that both loci are true positives for at least 153 traits. In addition, we are able to show that epistatic interactions contribute to gene expression variation for at least 14\% of all traits. We compare the proposed approach to an exhaustive two-dimensional scan over all pairs of loci. Surprisingly, we demonstrate that an exhaustive two-dimensional scan is less powerful than the sequential search used here. In addition, we show that a two-dimensional scan does not truly allow one to test for simultaneous linkage, and the statistical significance measured from this existing method cannot be interpreted among many traits.},
author = {Storey, John D and Akey, Joshua M and Kruglyak, Leonid},
doi = {10.1371/journal.pbio.0030267},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Storey, Akey, Kruglyak - 2005 - Multiple locus linkage analysis of genomewide expression in yeast.pdf:pdf},
issn = {1545-7885},
journal = {PLoS biology},
keywords = {Chromosome Mapping,Chromosome Mapping: methods,Epistasis,Fungal,Gene Expression Profiling,Genetic,Genetic Linkage,Genome,Phenotype,Probability,Quantitative Trait Loci,Saccharomyces cerevisiae,Saccharomyces cerevisiae: genetics},
month = aug,
number = {8},
pages = {e267},
pmid = {16035920},
title = {{Multiple locus linkage analysis of genomewide expression in yeast.}},
url = {http://dx.doi.org/10.1371/journal.pbio.0030267},
volume = {3},
year = {2005}
}
@article{Leek2010,
abstract = {High-throughput technologies are widely used, for example to assay genetic variants, gene and protein expression, and epigenetic modifications. One often overlooked complication with such studies is batch effects, which occur because measurements are affected by laboratory conditions, reagent lots and personnel differences. This becomes a major problem when batch effects are correlated with an outcome of interest and lead to incorrect conclusions. Using both published studies and our own analyses, we argue that batch effects (as well as other technical and biological artefacts) are widespread and critical to address. We review experimental and computational approaches for doing so.},
author = {Leek, Jeffrey T and Scharpf, Robert B and Bravo, H\'{e}ctor Corrada and Simcha, David and Langmead, Benjamin and Johnson, W Evan and Geman, Donald and Baggerly, Keith A and Irizarry, Rafael A},
doi = {10.1038/nrg2825},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Leek et al. - 2010 - Tackling the widespread and critical impact of batch effects in high-throughput data.pdf:pdf},
issn = {1471-0064},
journal = {Nature Reviews Genetics},
keywords = {Biotechnology,Biotechnology: methods,Biotechnology: standards,Biotechnology: statistics \& numerical data,Computational Biology,Computational Biology: methods,DNA,DNA: methods,DNA: standards,DNA: statistics \& numerical dat,Genomics,Genomics: methods,Genomics: standards,Genomics: statistics \& numerical data,Oligonucleotide Array Sequence Analysis,Oligonucleotide Array Sequence Analysis: methods,Oligonucleotide Array Sequence Analysis: standards,Oligonucleotide Array Sequence Analysis: statistic,Periodicals as Topic,Periodicals as Topic: standards,Research Design,Research Design: standards,Research Design: statistics \& numerical data,Sequence Analysis},
month = oct,
number = {10},
pages = {733--9},
pmid = {20838408},
publisher = {Nature Publishing Group},
title = {{Tackling the widespread and critical impact of batch effects in high-throughput data.}},
url = {http://dx.doi.org/10.1038/nrg2825},
volume = {11},
year = {2010}
}
@article{Eisen1998,
abstract = {A system of cluster analysis for genome-wide expression data from DNA microarray hybridization is described that uses standard statistical algorithms to arrange genes according to similarity in pattern of gene expression. The output is displayed graphically, conveying the clustering and the underlying expression data simultaneously in a form intuitive for biologists. We have found in the budding yeast Saccharomyces cerevisiae that clustering gene expression data groups together efficiently genes of known similar function, and we find a similar tendency in human data. Thus patterns seen in genome-wide expression experiments can be interpreted as indications of the status of cellular processes. Also, coexpression of genes of known function with poorly characterized or novel genes may provide a simple means of gaining leads to the functions of many genes for which information is not available currently.},
author = {Eisen, M B and Spellman, P T and Brown, P O and Botstein, D},
doi = {10.1073/pnas.95.25.14863},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Eisen et al. - 1998 - Cluster analysis and display of genome-wide expression patterns.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Cluster Analysis,Fungal,Gene Expression,Genome,Human,Humans,Multigene Family,Saccharomyces cerevisiae,Saccharomyces cerevisiae: genetics},
month = dec,
number = {25},
pages = {14863--8},
pmid = {9843981},
title = {{Cluster analysis and display of genome-wide expression patterns}},
url = {http://dx.doi.org/10.1073/pnas.95.25.14863},
volume = {95},
year = {1998}
}
@article{Baggerly2004a,
abstract = {There has been much interest in using patterns derived from surface-enhanced laser desorption and ionization (SELDI) protein mass spectra from serum to differentiate samples from patients both with and without disease. Such patterns have been used without identification of the underlying proteins responsible. However, there are questions as to the stability of this procedure over multiple experiments.},
author = {Baggerly, Keith a and Morris, Jeffrey S and Coombes, Kevin R},
doi = {10.1093/bioinformatics/btg484},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Baggerly, Morris, Coombes - 2004 - Reproducibility of SELDI-TOF protein patterns in serum comparing datasets from different experiments.pdf:pdf},
issn = {1367-4803},
journal = {Bioinformatics (Oxford, England)},
keywords = {Algorithms,Artifacts,Blood Proteins,Blood Proteins: analysis,Blood Proteins: chemistry,Blood Proteins: classification,Computer-Assisted,Computer-Assisted: methods,Computer-Assisted: standards,Databases,Diagnosis,Female,Humans,Lasers,Mass Spectrometry,Mass Spectrometry: methods,Mass Spectrometry: standards,Ovarian Neoplasms,Ovarian Neoplasms: blood,Ovarian Neoplasms: diagnosis,Protein,Protein: methods,Reproducibility of Results,Sensitivity and Specificity,Sequence Analysis,Software},
month = mar,
number = {5},
pages = {777--85},
pmid = {14751995},
title = {{Reproducibility of SELDI-TOF protein patterns in serum: comparing datasets from different experiments.}},
url = {http://dx.doi.org/10.1093/bioinformatics/btg484},
volume = {20},
year = {2004}
}
@article{Warmuth2008,
abstract = {We design an online algorithm for Principal Component Analysis. In each trial the current instance is centered and projected into a probabilistically chosen low dimensional subspace. The regret of our online algorithm, i.e. the total expected quadratic compression loss of the online algorithm minus the total quadratic compression loss of the batch algorithm, is bounded by a term whose dependence on the dimension of the instances is only logarithmic. We first develop our methodology in the expert setting of online learning by giving an algorithm for learning as well as the best subset of experts of a certain size. This algorithm is then lifted to the matrix setting where the subsets of experts correspond to subspaces. The algorithm represents the uncertainty over the best subspace as a density matrix whose eigenvalues are bounded. The running time is O(n²) per trial, where n is the dimension of the instances.},
author = {Warmuth, Manfred K and Kuzmin, Dima},
doi = {10.1.1.133.8332},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Warmuth, Kuzmin - 2008 - Randomized Online PCA Algorithms with Regret Bounds that are Logarithmic in the Dimension.pdf:pdf},
keywords = {density matrix,expert setting,online learning,principal component analysis,quantum},
pages = {2287--2320},
title = {{Randomized Online PCA Algorithms with Regret Bounds that are Logarithmic in the Dimension}},
url = {http://jmlr.csail.mit.edu/papers/volume9/warmuth08a/warmuth08a.pdf},
volume = {9},
year = {2008}
}
@article{Chan2011,
abstract = {Personalized medicine is a broad and rapidly advancing field of health care that is informed by each person's unique clinical, genetic, genomic, and environmental information. Personalized medicine depends on multidisciplinary health care teams and integrated technologies (e.g., clinical decision support) to utilize our molecular understanding of disease in order to optimize preventive health care strategies. Human genome information now allows providers to create optimized care plans at every stage of a disease, shifting the focus from reactive to preventive health care. The further integration of personalized medicine into the clinical workflow requires overcoming several barriers in education, accessibility, regulation, and reimbursement. This review focuses on providing a comprehensive understanding of personalized medicine, from scientific discovery at the laboratory bench to integration of these novel ways of understanding human biology at the bedside.},
author = {Chan, Isaac S and Ginsburg, Geoffrey S},
doi = {10.1146/annurev-genom-082410-101446},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Chan, Ginsburg - 2011 - Personalized medicine progress and promise.pdf:pdf},
isbn = {0824101014},
issn = {1545-293X},
journal = {Annual review of genomics and human genetics},
keywords = {Disease,Disease: genetics,Genetic Predisposition to Disease,Genome,Human,Humans,Individualized Medicine,Pharmacogenetics,Preventive Medicine},
month = sep,
pages = {217--44},
pmid = {21721939},
title = {{Personalized medicine: progress and promise.}},
url = {http://dx.doi.org/10.1146/annurev-genom-082410-101446},
volume = {12},
year = {2011}
}
@article{Baggerly2005,
abstract = {Proteomic patterns derived from mass spectrometry have recently been put forth as potential biomarkers for the early diagnosis of cancer. This approach has generated much excitement, particularly as initial results reported on SELDI profiling of serum suggested that near perfect sensitivity and specificity could be achieved in diagnosing ovarian cancer. However, more recent reports have suggested that much of the observed structure could be due to the presence of experimental bias. A rebuttal to the findings of bias, subtitled "Producers and Consumers", lists several objections. In this paper, we attempt to address these objections. While we continue to find evidence of experimental bias, we emphasize that the problems found are associated with experimental design and processing, and can be avoided in future studies.},
author = {Baggerly, Keith a and Coombes, Kevin R and Morris, Jeffrey S},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Baggerly, Coombes, Morris - 2005 - Bias, randomization, and ovarian proteomic data a reply to producers and consumers.pdf:pdf},
issn = {1176-9351},
journal = {Cancer informatics},
keywords = {calibration,experimental design,mass spectrometry,proteomics,serum profi ling},
month = jan,
number = {2003},
pages = {9--14},
pmid = {19305627},
title = {{Bias, randomization, and ovarian proteomic data: a reply to "producers and consumers"}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19305627},
volume = {1},
year = {2005}
}
@article{Piccolo2012,
abstract = {Gene-expression microarrays allow researchers to characterize biological phenomena in a high-throughput fashion but are subject to technological biases and inevitable variabilities that arise during sample collection and processing. Normalization techniques aim to correct such biases. Most existing methods require multiple samples to be processed in aggregate; consequently, each sample's output is influenced by other samples processed jointly. However, in personalized-medicine workflows, samples may arrive serially, so renormalizing all samples upon each new arrival would be impractical. We have developed Single Channel Array Normalization (SCAN), a single-sample technique that models the effects of probe-nucleotide composition on fluorescence intensity and corrects for such effects, dramatically increasing the signal-to-noise ratio within individual samples while decreasing variation across samples. In various benchmark comparisons, we show that SCAN performs as well as or better than competing methods yet has no dependence on external reference samples and can be applied to any single-channel microarray platform.},
author = {Piccolo, Stephen R. and Sun, Ying and Campbell, Joshua D. and Lenburg, Marc E. and Bild, Andrea H. and Johnson, W. Evan},
doi = {10.1016/j.ygeno.2012.08.003},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Piccolo et al. - 2012 - A single-sample microarray normalization method to facilitate personalized-medicine workflows.pdf:pdf},
issn = {08887543},
journal = {Genomics},
keywords = {Linear model,Method,Microarray,Mixture model,Normalization,Single-sample technique},
month = aug,
publisher = {Elsevier Inc.},
title = {{A single-sample microarray normalization method to facilitate personalized-medicine workflows}},
url = {http://dx.doi.org/10.1016/j.ygeno.2012.08.003},
year = {2012}
}
@article{Lander1999,
author = {Lander, E S},
doi = {10.1038/4427},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Lander - 1999 - Array of hope.pdf:pdf},
issn = {1061-4036},
journal = {Nature genetics},
keywords = {Animals,DNA,DNA: analysis,Gene Expression,Genetic Variation,Genome,Humans,Messenger,Messenger: analysis,Molecular Probe Techniques,Molecular Probe Techniques: trends,Oligonucleotide Array Sequence Analysis,Oligonucleotide Array Sequence Analysis: methods,RNA,Saccharomyces cerevisiae,Saccharomyces cerevisiae: genetics},
month = jan,
number = {1 Suppl},
pages = {3--4},
pmid = {9915492},
title = {{Array of hope.}},
url = {http://dx.doi.org/10.1038/4427},
volume = {21},
year = {1999}
}
@article{Leek2012b,
abstract = {SUMMARY: Heterogeneity and latent variables are now widely recognized as major sources of bias and variability in high-throughput experiments. The most well-known source of latent variation in genomic experiments are batch effects - when samples are processed on different days, in different groups, or by different people. However, there are also a large number of other variables that may have a major impact on high-throughput measurements. Here we describe the sva package for identifying, estimating, and removing unwanted sources of variation in high-throughput experiments. The sva package supports surrogate variable estimation with the sva function, direct adjustment for known batch effects with the ComBat function, and adjustment for batch and latent variables in prediction problems with the fsva function. AVAILABILITY: The R package sva is freely available from http://www.bioconductor.org. CONTACT: jleek@jhsph.edu.},
author = {Leek, Jeffrey T and Johnson, W Evan and Parker, Hilary S and Jaffe, Andrew E and Storey, John D},
doi = {10.1093/bioinformatics/bts034},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Leek et al. - 2012 - The sva package for removing batch effects and other unwanted variation in high-throughput experiments.pdf:pdf},
issn = {1367-4811},
journal = {Bioinformatics},
month = jan,
number = {6},
pages = {882----883},
pmid = {22257669},
title = {{The sva package for removing batch effects and other unwanted variation in high-throughput experiments}},
url = {http://dx.doi.org/10.1093/bioinformatics/bts034},
volume = {28},
year = {2012}
}
@article{Tibshirani2002,
abstract = {We have devised an approach to cancer class prediction from gene expression profiling, based on an enhancement of the simple nearest prototype (centroid) classifier. We shrink the prototypes and hence obtain a classifier that is often more accurate than competing methods. Our method of "nearest shrunken centroids" identifies subsets of genes that best characterize each class. The technique is general and can be used in many other classification problems. To demonstrate its effectiveness, we show that the method was highly efficient in finding genes for classifying small round blue cell tumors and leukemias.},
annote = {Stanford website: http://www-stat.stanford.edu/\~{}tibs/PAM/          
          
                                  Basic idea from paper:                                  
                
"The methods described here can identify minimal subsets of the genes that succinctly characterize each cluster." 
        
"Our goal of our method is to find the smallest set of genes that can accurately classify samples." 
        
"The method of nearest shrunken centroids was successful in finding genes that accurately predict classes."
        
43 genes were able to assign tumors to one of four classes with 100\% accuracy. 
        
                                      
Overview of PAM method:                                  
                
- Shrink class centroids (i.e. mean for a given class for a given gene) toward the overall centroid (mean for a given gene) after standardizing by the within-class standard deviation for each gene. (Gives higher weight to lower variance genes). This creates a t statistic for gene i comparing class k to the overall centroid. 
        
-This test statistic is shrunken by a delta value, which is derived from the data. If the resulting value is less than zero, the test statistic is set to zero (which is why so few genes are found to be expressed using this method). 
        
-The class centroid is then calculated from the overall centroid, plus this new test statistic (multiplied by a few things). Advantage is that if a gene is shrunken to zero for all classes, then the centroid for gene i is the same for all classes. 
        
-After the class centroids are shrunken, one calculates a discriminant score for class k (based on the expression levels for each class minus the shrunken centroid, and incorporates the prior probability for being in class k). Priors are usually estimated by the sample priors. Could also use equal priors. 
        
-Use the discriminant score for each class to calculate estimates of the class probabilities for each sample. Figure in the paper shows very, very clear discrimination between classes for each of the 34 samples. },
author = {Tibshirani, Robert and Hastie, Trevor and Narasimhan, Balasubramanian and Chu, Gilbert},
doi = {10.1073/pnas.082099299},
file = {:C$\backslash$:/Users/Hilary/Documents/Mendeley/Tibshirani et al. - 2002 - Diagnosis of multiple cancer types by shrunken centroids of gene expression.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Child,DNA,Discriminant Analysis,Gene Expression,Gene Expression Profiling,Humans,Neoplasm,Neoplasm: analysis,Neoplasms,Neoplasms: classification,Neoplasms: diagnosis,Neoplasms: genetics,Precursor Cell Lymphoblastic Leukemia-Lymphoma,Precursor Cell Lymphoblastic Leukemia-Lymphoma: cl,Precursor Cell Lymphoblastic Leukemia-Lymphoma: di,Precursor Cell Lymphoblastic Leukemia-Lymphoma: ge,Probability},
month = may,
number = {10},
pages = {6567--72},
pmid = {12011421},
title = {{Diagnosis of multiple cancer types by shrunken centroids of gene expression}},
url = {http://dx.doi.org/10.1073/pnas.082099299},
volume = {99},
year = {2002}
}
